{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nimport pandas as pd\nimport seaborn as sns\nimport pickle\nimport random\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# The pickle module implements binary protocols for serializing and de-serializing a Python object structure.\n\nwith open(\"/kaggle/input/traffic-sign-classification/train.p\", mode='rb') as training_data:\n    train = pickle.load(training_data)\nwith open(\"/kaggle/input/traffic-sign-classification/valid.p\", mode='rb') as validation_data:\n    valid = pickle.load(validation_data)\nwith open(\"/kaggle/input/traffic-sign-classification/test.p\", mode='rb') as testing_data:\n    test = pickle.load(testing_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train = train['features'], train['labels']\nX_validation, y_validation = valid['features'], valid['labels']\nX_test,y_test= test['features'],test['labels']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"wee 34799 images with 32pixcel ,32 pixcel ,3"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=np.random.randint(1,len(X_train))\nplt.imshow(X_train[i])\ny_train[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# more images in a grid format\n# the dimensions of the plot grid \nW_grid = 10\nL_grid = 10\n\n# fig, axes = plt.subplots(L_grid, W_grid)\n# subplot return the figure object and axes object\n# we can use the axes object to plot specific figures at various locations\n\nfig, axes = plt.subplots(L_grid, W_grid, figsize = (10,10))\n\naxes = axes.ravel() # flaten the 5 x 5 matrix into 25 array\n\nn_training = len(X_train) # get the length of the training dataset\n\n# Select a random number from 0 to n_training\n#  evenly spaces variables\nfor i in np.arange(0,W_grid * L_grid):\n\n# Select a random number\n    index=np.random.randint(0,n_training)\n    \n\n# read and display an image with the selected index\n\n    axes[i].imshow(X_train[index])\n    axes[i].set_title(y_train[index],fontsize=15)\n    axes[i].axis('off')\nplt.subplots_adjust(hspace = 0.4)\n    \n    \n\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA PEPARATION "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Shuffle the dataset \nfrom sklearn.utils import shuffle\nX_train,y_train = shuffle(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_gray = np.sum(X_train/3, axis=3, keepdims=True)\nX_test_gray  = np.sum(X_test/3, axis=3, keepdims=True)\nX_validation_gray  = np.sum(X_validation/3, axis=3, keepdims=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_gray_norm = (X_train_gray - 128)/128 \nX_test_gray_norm = (X_test_gray - 128)/128\nX_validation_gray_norm = (X_validation_gray - 128)/128\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = random.randint(1, len(X_train_gray))\nplt.imshow(X_train_gray[i].squeeze(), cmap = 'gray')\nplt.figure()\nplt.imshow(X_train[i])\nplt.figure()\nplt.imshow(X_train_gray_norm[i].squeeze(), cmap = 'gray')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # BUILD DEEP CONVOLUTIONAL NEURAL NETWORK MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import datasets, layers, models\nCNN =models.Sequential()\n\nCNN.add(layers.Conv2D(6, (5, 5), activation='relu', input_shape = (32,32,1)))\nCNN.add(layers.AveragePooling2D())\n\nCNN.add(layers.Conv2D(16, (5, 5), activation='relu'))\nCNN.add(layers.AveragePooling2D())\n\n\nCNN.add(layers.Dropout(0.2))\n\nCNN.add(layers.Flatten())\n\nCNN.add(layers.Dense(120, activation = 'relu'))\nCNN.add(layers.Dense(84, activation = 'relu'))\nCNN.add(layers.Dense(43, activation = 'softmax'))\nCNN.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# COMPILE AND TRAIN DEEP CNN MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"CNN.compile(optimizer = 'Adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = CNN.fit(X_train_gray_norm,\n                  y_train,\n                  batch_size = 500,\n                  epochs = 50,\n                  verbose = 1,\n                  validation_data = (X_validation_gray_norm,y_validation))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ASSESS TRAINED CNN MODEL PERFORMANCE "},{"metadata":{"trusted":true},"cell_type":"code","source":"score = CNN.evaluate(X_test_gray_norm, y_test)\nprint('Test Accuracy: {}'.format(score[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history.history.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = range(len(accuracy))\nplt.plot(epochs,loss,'ro',label = 'Traning loss')\nplt.plot(epochs,val_loss,'r',label = 'Validation loss')\nplt.title('Traning and Validation loss')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = range(len(accuracy))\nplt.plot(epochs,accuracy,'ro',label = 'Traning accuarcy')\nplt.plot(epochs,val_accuracy,'r',label = 'Validation accuracy')\nplt.title('Traning and Validation accuracy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_classes = CNN.predict_classes(X_test_gray_norm)\ny_true = y_test\n\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true, predicted_classes)\nplt.figure(figsize = (25, 25))\nsns.heatmap(cm, annot = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"L = 5\nW = 5\n\nfig, axes = plt.subplots(L, W, figsize = (12, 12))\naxes = axes.ravel()\n\nfor i in np.arange(0, L*W):\n    axes[i].imshow(X_test[i])\n    axes[i].set_title('Prediction = {}\\n True = {}'.format(predicted_classes[i], y_true[i]))\n    axes[i].axis('off')\n\nplt.subplots_adjust(wspace = 1)    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# APPENDIX"},{"metadata":{},"cell_type":"markdown","source":"- In this case study, we want to classify images of traffic signs using deep Convolutional Neural Networks (CNNs).\n- The dataset consists of 43 different classes of images. \n- Classes are as listed below: \n  - 0 = Speed limit (20km/h) \n  - 1 = Speed limit (30km/h)\n  - 2 = Speed limit (50km/h) \n  - 3 = Speed limit (60km/h)\n  - 4 = Speed limit (70km/h) \n  - 5 = Speed limit (80km/h)\n  - 6 = End of speed limit (80km/h)\n  - 7 = Speed limit (100km/h)\n  - 8 = Speed limit (120km/h)\n  - 9 = No passing\n  - 10 = No passing for vehicles over 3.5 metric tons\n  - 11 = Right-of-way at the next intersection\n  - 12 = Priority road\n  - 13 = Yield\n  - 14 = Stop\n  - 15 = No vehicles\n  - 16 = Vehicles over 3.5 metric tons prohibited\n  - 17 = No entry\n  - 18 = General caution\n  - 19 = Dangerous curve to the left\n  - 20 = Dangerous curve to the right\n  - 21 = Double curve\n  - 22 = Bumpy road\n  - 23 = Slippery road\n  - 24 = Road narrows on the right\n  - 25 = Road work\n  - 26 = Traffic signals\n  - 27 = Pedestrians\n  - 28 = Children crossing \n  - 29 = Bicycles crossing\n  - 30 = Beware of ice/snow\n  - 31 = Wild animals crossing\n  - 32 = End of all speed and passing limits\n  - 33 = Turn right ahead\n  - 34 = Turn left ahead\n  - 35 = Ahead only\n  - 36 = Go straight or right\n  - 37 = Go straight or left\n  - 38 = Keep right\n  - 39 = Keep left\n  - 40 = Roundabout mandatory\n  - 41 = End of no passing\n  - 42 = End of no passing by vehicles over 3.5 metric tons\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
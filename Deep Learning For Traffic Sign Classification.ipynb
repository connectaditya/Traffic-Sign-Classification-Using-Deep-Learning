{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aadi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Aadi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Aadi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Aadi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Aadi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Aadi\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Aadi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Aadi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Aadi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Aadi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Aadi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Aadi\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/train.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-079455184aba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# The pickle module implements binary protocols for serializing and de-serializing a Python object structure.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/train.p\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/valid.p\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/train.p'"
     ]
    }
   ],
   "source": [
    "# The pickle module implements binary protocols for serializing and de-serializing a Python object structure.\n",
    "\n",
    "with open(\"/train.p\", mode='rb') as training_data:\n",
    "    train = pickle.load(training_data)\n",
    "with open(\"/valid.p\", mode='rb') as validation_data:\n",
    "    valid = pickle.load(validation_data)\n",
    "with open(\"/test.p\", mode='rb') as testing_data:\n",
    "    test = pickle.load(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = train['features'], train['labels']\n",
    "X_validation, y_validation = valid['features'], valid['labels']\n",
    "X_test,y_test= test['features'],test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wee 34799 images with 32pixcel ,32 pixcel ,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=np.random.randint(1,len(X_train))\n",
    "plt.imshow(X_train[i])\n",
    "y_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more images in a grid format\n",
    "# the dimensions of the plot grid \n",
    "W_grid = 10\n",
    "L_grid = 10\n",
    "\n",
    "# fig, axes = plt.subplots(L_grid, W_grid)\n",
    "# subplot return the figure object and axes object\n",
    "# we can use the axes object to plot specific figures at various locations\n",
    "\n",
    "fig, axes = plt.subplots(L_grid, W_grid, figsize = (10,10))\n",
    "\n",
    "axes = axes.ravel() # flaten the 5 x 5 matrix into 25 array\n",
    "\n",
    "n_training = len(X_train) # get the length of the training dataset\n",
    "\n",
    "# Select a random number from 0 to n_training\n",
    "#  evenly spaces variables\n",
    "for i in np.arange(0,W_grid * L_grid):\n",
    "\n",
    "# Select a random number\n",
    "    index=np.random.randint(0,n_training)\n",
    "    \n",
    "\n",
    "# read and display an image with the selected index\n",
    "\n",
    "    axes[i].imshow(X_train[index])\n",
    "    axes[i].set_title(y_train[index],fontsize=15)\n",
    "    axes[i].axis('off')\n",
    "plt.subplots_adjust(hspace = 0.4)\n",
    "    \n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PEPARATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset \n",
    "from sklearn.utils import shuffle\n",
    "X_train,y_train = shuffle(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gray = np.sum(X_train/3, axis=3, keepdims=True)\n",
    "X_test_gray  = np.sum(X_test/3, axis=3, keepdims=True)\n",
    "X_validation_gray  = np.sum(X_validation/3, axis=3, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gray_norm = (X_train_gray - 128)/128 \n",
    "X_test_gray_norm = (X_test_gray - 128)/128\n",
    "X_validation_gray_norm = (X_validation_gray - 128)/128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = random.randint(1, len(X_train_gray))\n",
    "plt.imshow(X_train_gray[i].squeeze(), cmap = 'gray')\n",
    "plt.figure()\n",
    "plt.imshow(X_train[i])\n",
    "plt.figure()\n",
    "plt.imshow(X_train_gray_norm[i].squeeze(), cmap = 'gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # BUILD DEEP CONVOLUTIONAL NEURAL NETWORK MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets, layers, models\n",
    "CNN =models.Sequential()\n",
    "\n",
    "CNN.add(layers.Conv2D(6, (5, 5), activation='relu', input_shape = (32,32,1)))\n",
    "CNN.add(layers.AveragePooling2D())\n",
    "\n",
    "CNN.add(layers.Conv2D(16, (5, 5), activation='relu'))\n",
    "CNN.add(layers.AveragePooling2D())\n",
    "\n",
    "\n",
    "CNN.add(layers.Dropout(0.2))\n",
    "\n",
    "CNN.add(layers.Flatten())\n",
    "\n",
    "CNN.add(layers.Dense(120, activation = 'relu'))\n",
    "CNN.add(layers.Dense(84, activation = 'relu'))\n",
    "CNN.add(layers.Dense(43, activation = 'softmax'))\n",
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPILE AND TRAIN DEEP CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN.compile(optimizer = 'Adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = CNN.fit(X_train_gray_norm,\n",
    "                  y_train,\n",
    "                  batch_size = 500,\n",
    "                  epochs = 50,\n",
    "                  verbose = 1,\n",
    "                  validation_data = (X_validation_gray_norm,y_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSESS TRAINED CNN MODEL PERFORMANCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = CNN.evaluate(X_test_gray_norm, y_test)\n",
    "print('Test Accuracy: {}'.format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs,loss,'ro',label = 'Traning loss')\n",
    "plt.plot(epochs,val_loss,'r',label = 'Validation loss')\n",
    "plt.title('Traning and Validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(len(accuracy))\n",
    "plt.plot(epochs,accuracy,'ro',label = 'Traning accuarcy')\n",
    "plt.plot(epochs,val_accuracy,'r',label = 'Validation accuracy')\n",
    "plt.title('Traning and Validation accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = CNN.predict_classes(X_test_gray_norm)\n",
    "y_true = y_test\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, predicted_classes)\n",
    "plt.figure(figsize = (25, 25))\n",
    "sns.heatmap(cm, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 5\n",
    "W = 5\n",
    "\n",
    "fig, axes = plt.subplots(L, W, figsize = (12, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in np.arange(0, L*W):\n",
    "    axes[i].imshow(X_test[i])\n",
    "    axes[i].set_title('Prediction = {}\\n True = {}'.format(predicted_classes[i], y_true[i]))\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace = 1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPENDIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this case study, we want to classify images of traffic signs using deep Convolutional Neural Networks (CNNs).\n",
    "- The dataset consists of 43 different classes of images. \n",
    "- Classes are as listed below: \n",
    "  - 0 = Speed limit (20km/h) \n",
    "  - 1 = Speed limit (30km/h)\n",
    "  - 2 = Speed limit (50km/h) \n",
    "  - 3 = Speed limit (60km/h)\n",
    "  - 4 = Speed limit (70km/h) \n",
    "  - 5 = Speed limit (80km/h)\n",
    "  - 6 = End of speed limit (80km/h)\n",
    "  - 7 = Speed limit (100km/h)\n",
    "  - 8 = Speed limit (120km/h)\n",
    "  - 9 = No passing\n",
    "  - 10 = No passing for vehicles over 3.5 metric tons\n",
    "  - 11 = Right-of-way at the next intersection\n",
    "  - 12 = Priority road\n",
    "  - 13 = Yield\n",
    "  - 14 = Stop\n",
    "  - 15 = No vehicles\n",
    "  - 16 = Vehicles over 3.5 metric tons prohibited\n",
    "  - 17 = No entry\n",
    "  - 18 = General caution\n",
    "  - 19 = Dangerous curve to the left\n",
    "  - 20 = Dangerous curve to the right\n",
    "  - 21 = Double curve\n",
    "  - 22 = Bumpy road\n",
    "  - 23 = Slippery road\n",
    "  - 24 = Road narrows on the right\n",
    "  - 25 = Road work\n",
    "  - 26 = Traffic signals\n",
    "  - 27 = Pedestrians\n",
    "  - 28 = Children crossing \n",
    "  - 29 = Bicycles crossing\n",
    "  - 30 = Beware of ice/snow\n",
    "  - 31 = Wild animals crossing\n",
    "  - 32 = End of all speed and passing limits\n",
    "  - 33 = Turn right ahead\n",
    "  - 34 = Turn left ahead\n",
    "  - 35 = Ahead only\n",
    "  - 36 = Go straight or right\n",
    "  - 37 = Go straight or left\n",
    "  - 38 = Keep right\n",
    "  - 39 = Keep left\n",
    "  - 40 = Roundabout mandatory\n",
    "  - 41 = End of no passing\n",
    "  - 42 = End of no passing by vehicles over 3.5 metric tons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
